{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "08fecd06cada05dc2b74c825e68b8924",
     "grade": false,
     "grade_id": "cell-e37bf3469fc1e9d7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All). Do NOT add any cells to the notebook!\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or _YOUR ANSWER HERE_ , as well as your name and group below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Christoph Helmberger\"\n",
    "# Pls indicate your student id as a string, w/o the leading 'h'!\n",
    "student_id = \"11915039\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0889b39dada38cf936d0f8a4d62f12a2",
     "grade": false,
     "grade_id": "cell-547da1b1777ed8e0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Assignment 3 (Individual)\n",
    "\n",
    "In continuation of Assignment 2, we will now practice how to process datasets.\n",
    "From what you have seen in the lecture you should practice the following steps:\n",
    "* basic dataset decription & assessing \"tidyness\"\n",
    "* filtering\n",
    "* sorting\n",
    "* aggregation\n",
    "using both \"pure\" Python and also using Pandas. \n",
    "-----\n",
    "\n",
    "## Step 1a (4 points)\n",
    "\n",
    "Find a CSV dataset online (same requirements apply as in Assignment 2), but additionally make sure that the dataset has at least  one column with a categorical value and one column with a numerical value. Note, if you worked in a group, you as group members are NOT allowed to use the same dataset, i.e., we expect everybody to find their own CSV file.\n",
    "Save the file into your data folder and name it __data_notebook-1_DataFile.csv__.\n",
    "\n",
    "To avoid any unexpected errors when running your submission in our grading environment, we highly recommend a dataset which uses the encoding `utf-8`.\n",
    "\n",
    "Using the CSV package, write the function `analyzeCSV` to return:\n",
    "* the number of rows in the dataset.\n",
    "* how many different __values__ and which __datatype__ appears per column in the CSV file.\n",
    "\n",
    "That is, the function should return a dictionary of the following structure:\n",
    "```\n",
    " {\n",
    "  \"rows\": ..., # the number of rows (integer)\n",
    "  \"columns\": ... # a list of pairs [ (v_1,dt_1) , (v_2,dt_2), ... (v_1,dt_1)]\n",
    " }  \n",
    "```\n",
    "where `(v_i,dt_i)` denotes the number of different values (`v_i`), and the datatype (`dt_i`) detected in column `i`.\n",
    "If you detect several different datatypes per column your function should return the value `\"object\"` for `dt_i`.\n",
    "\n",
    "__Hint__: For the (heuristic) datatype detection per column, you can use/adapt the function `convert()` from notebook `unit3/00_value-transformation.ipynb` from the lecture, i.e., possible returned values apart from the string `\"object\"` should be the return value of the `type()` function applied to the heuristically converted values in the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "98466af8549136ebfb5c2b1dd7257438",
     "grade": false,
     "grade_id": "cell-888abc9fb6a6b742",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "filePath = \"./data/data_notebook-1_DataFile.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a3f4ec8092cbb64a8f4b9fb9546e6d40",
     "grade": false,
     "grade_id": "cell-8e80d24157bdcf2b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "heuristics = [lambda value: datetime.strptime(value, \"%Y-%m-%d\"), lambda value: datetime.strptime(value, \"%Y%m%d\"),\n",
    "              int, float]\n",
    "\n",
    "def convert(value):\n",
    "    for type in heuristics:\n",
    "        try:\n",
    "            return type(value)\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "    return value\n",
    "\n",
    "def analyzeCSV(filePath):\n",
    "    with open(filePath, newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        data = list(reader)\n",
    "\n",
    "    columns=[]\n",
    "    header=data[0]\n",
    "    \n",
    "    # Counter starts with one because the header row will not appear in the for loop\n",
    "    rowcount = 1\n",
    "    for row in data[1:]:\n",
    "        rowcount += 1\n",
    "        d={}\n",
    "        for i,h in enumerate(header):\n",
    "            d[h]=row[i]\n",
    "        columns.append(d)\n",
    "\n",
    "    columns={}\n",
    "    header=data[0]\n",
    "    columns={ h:[] for h in header}\n",
    "\n",
    "    for city in data[1:]:\n",
    "        for i,h in enumerate(header): \n",
    "            if str(city[i]) != \"\":\n",
    "                columns[h].append(city[i])\n",
    "    \n",
    "    columnValues = []\n",
    "    for key, value in columns.items():\n",
    "        columnValues.append({key : set(value)})\n",
    "    \n",
    "    returnColumns = []\n",
    "    for d in columnValues:\n",
    "        dataType = []\n",
    "        \n",
    "        for key, value in d.items():\n",
    "            for v in value:\n",
    "                dataType.append(type(convert(v)))\n",
    "                if len(set(dataType)) > 1:\n",
    "                    dataType.clear()\n",
    "                    dataType.append(\"object\")\n",
    "                    break\n",
    "                    \n",
    "        returnColumns.append((len(value), dataType[0]))           \n",
    "            \n",
    "    return {\"rows\": rowcount, \"columns\": returnColumns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "936de7114bd44814964a6390ef5ceee4",
     "grade": true,
     "grade_id": "cell-ab8cd6999e00795a",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from nose.tools import assert_equal\n",
    "assert_equal(type(analyzeCSV(filePath)), dict)\n",
    "assert_equal(len(analyzeCSV(filePath)), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5459615ccac8ff8d8eacfa0e3d3b964e",
     "grade": false,
     "grade_id": "cell-0601eda65c85a474",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now, (potentially using some more manual inspection), answer the following questions:\n",
    "* Which types of variables appear in this dateset? For each variable, indicate whether\n",
    "  *  it is nominal or categorical, \n",
    "  *  it is an identifier, a dimension or a measurement.  \n",
    "* How would you describe an \"observation\" in this dataset?\n",
    "* Is the dataset tidy?\n",
    "* If no, why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "95b0f6134ade6ae1b5f2bc193b820d77",
     "grade": true,
     "grade_id": "cell-f2d935f6c5393e81",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "* Six variables: Reporting country, Reference period, Item, Item code, Value, Date of extraction (yyyymmdd)\n",
    "* Types of variables:\n",
    "    * Reporting country: categorical, dimension\n",
    "    * Reference period: nominal, dimension\n",
    "    * Item: categorical, dimension\n",
    "    * Item code: categorical, identifier\n",
    "    * Value: nominal, measurement\n",
    "    * Date of extraction (yyyymmdd): nominal, derived variable\n",
    "    \n",
    "* Observation: One observation describes the expenses from an insurance company in a specific country as purpose of prudential reporting data\n",
    "\n",
    "* The dataset is tidy, because there are no values missing, each variable is a column and each observation forms a row\n",
    "\n",
    "* Dataset:\n",
    "    * Downloaded on this page under the header \"Premiums, claims and expenses\": https://data.europa.eu/data/datasets/eiopa-insurance-statistics-solo-annual?locale=en\n",
    "    * CSV-Link: https://register.eiopa.europa.eu/Publications/Insurance%20Statistics/SA_Own_Funds.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a0abbb024bceeb815544ffdb422331cf",
     "grade": false,
     "grade_id": "cell-92fae8cb742fa6bd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Step 1b (2 points)\n",
    "\n",
    "Now, perform the same steps you solved in 1a using pandas, i.e., read in the CSV file and write the function `pandalyzeCSV` that computes the same structure as defined in 1a.\n",
    "\n",
    "__Hint:__ pandas dataframes provide the useful function `nunique()` to compute the number of unique values in a column (`v_i`) as well as the attribute  `dtypes` to get the column datatypes (`dt_i`), which you should use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5d1a29a6faeeed268548ff9c5323b682",
     "grade": false,
     "grade_id": "cell-51b966c1b26d93c8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def pandalyzeCSV(filePath):\n",
    "    df_csv = pd.read_csv(filePath)\n",
    "    \n",
    "    dictOccurens = {}\n",
    "    for key, value in df_csv.nunique().items():\n",
    "        dictOccurens[key] = value\n",
    "        \n",
    "    dictType = {}\n",
    "    for key, value in df_csv.dtypes.items():\n",
    "        dictType[key] = str(value)\n",
    "\n",
    "    returnColumns = []\n",
    "    for key, value in dictOccurens.items():\n",
    "        returnColumns.append((value, dictType[key]))\n",
    "\n",
    "    return {\"rows\": len(df_csv.index), \"columns\": returnColumns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9c69d996b4f3071cd42c4cc5279e9368",
     "grade": true,
     "grade_id": "cell-aebcdbed198ea4b4",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from nose.tools import assert_equal\n",
    "assert_equal(type(pandalyzeCSV(filePath)), dict)\n",
    "assert_equal(len(pandalyzeCSV(filePath)), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b34db910b10ccacd34f814a3bc946799",
     "grade": false,
     "grade_id": "cell-763a3cdfc1a5447d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Step 2a Filtering (2 points)\n",
    "\n",
    "Using pure Python, i.e. NOT using pandas, write the function `csvFilter` that should:\n",
    "* convert the CSV to a list of lists,\n",
    "* filter the rows of the dataset on the numeric column with the most unique values (if there are several columns with the same number of unique values, take the left-most of those) by showing all rows where the value of this column is smaller than the column's mean\n",
    "* return the list of lists containing only the filtered rows and not containing a header!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "57cf7c78479bf4e144dba1b928cbf679",
     "grade": false,
     "grade_id": "cell-3e8023888dd8a9c3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def csvFilter(filePath):\n",
    "    with open(filePath, newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        data = list(reader)\n",
    "    \n",
    "    #get rid of header row\n",
    "    data.pop(0)\n",
    "    \n",
    "    dataInfos = analyzeCSV(filePath)\n",
    "    \n",
    "    numColumnIndex = {}\n",
    "    for d in dataInfos[\"columns\"]:\n",
    "        if d[1] == int or d[1] == float:          \n",
    "            if bool(numColumnIndex) == False or d[0] > numColumnIndex[\"number\"]:\n",
    "                numColumnIndex[\"number\"] = d[0]\n",
    "                numColumnIndex[\"index\"] = dataInfos[\"columns\"].index(d)\n",
    "    \n",
    "    returnList = []\n",
    "    \n",
    "    if bool(numColumnIndex) == True:       \n",
    "        summation = 0.0\n",
    "        for d in data:\n",
    "            summation = summation + float(d[numColumnIndex[\"index\"]])\n",
    "        mean = summation / len(data)\n",
    "        \n",
    "        for d in data:\n",
    "            if float(d[numColumnIndex[\"index\"]]) < mean:\n",
    "                returnList.append(d)\n",
    "    \n",
    "    return returnList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nose.tools import assert_equal\n",
    "assert_equal(type(csvFilter(filePath)), list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "20865cf2496552f49e2147309c6c56c6",
     "grade": false,
     "grade_id": "cell-ccb23da90625904d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Step 2b Filtering - pandas (2 points)\n",
    "\n",
    "Now, again using pandas, write the function `pandasFilter` to:\n",
    "* convert the dataset to a pandas dataframe\n",
    "* filter the rows of the dataset by the same condition as for 2a:\n",
    "* return the pandas dataframe only containing the filtered rows!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cf97ad62f8d6908c41fd53bef11b3a19",
     "grade": false,
     "grade_id": "cell-4822ef9f00f9e26c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def pandasFilter(filePath):\n",
    "    df = pd.read_csv(filePath)\n",
    "    \n",
    "    dictOccurens = {}\n",
    "    for key, value in df.nunique().items():\n",
    "        dictOccurens[key] = value\n",
    "        \n",
    "    dictType = {}\n",
    "    for key, value in df.dtypes.items():\n",
    "        dictType[key] = str(value)\n",
    "    \n",
    "    dfTypes = df.select_dtypes(include=['int64','float64'])\n",
    "    \n",
    "    filterColumn = {}\n",
    "    \n",
    "    for c in dfTypes.columns.values:\n",
    "        if bool(filterColumn) == False or dictOccurens[c] > filterColumn[\"uniqueValues\"]:\n",
    "            filterColumn[\"columnName\"] = c\n",
    "            filterColumn[\"uniqueValues\"] = dictOccurens[c]\n",
    "    \n",
    "    dfFiltered = df[df[filterColumn[\"columnName\"]] < df[filterColumn[\"columnName\"]].mean()]\n",
    "    \n",
    "    return dfFiltered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6665d77107c94e0a2bd35950c5e8706a",
     "grade": true,
     "grade_id": "cell-4e7f425477a41440",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from nose.tools import assert_equal\n",
    "assert_equal(type(pandasFilter(filePath)), pd.DataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8e60a7d0b75ec17af51db5713a182f1b",
     "grade": false,
     "grade_id": "cell-8c1be8eef825aa09",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Step 3a Sorting (2 points)\n",
    "\n",
    "Using pure Python, i.e. NOT using pandas:\n",
    "* define a function sortCSV(filePath) which sorts the rows of your csv file by the left-most non-numerical in descending order of values. \n",
    "* The function takes *filePath* as input (which you have already defined above).\n",
    "* Your function should return the sorted contents of the CSV file as a list of lists.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2fa58b29ef0ffba5e526a3a813b23831",
     "grade": false,
     "grade_id": "cell-987ea095365b9681",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def sortCSV(filePath):\n",
    "    with open(filePath, newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        data = list(reader)\n",
    "    \n",
    "    #get rid of header row\n",
    "    data.pop(0)\n",
    "    \n",
    "    dataInfos = analyzeCSV(filePath)\n",
    "    \n",
    "    columnIndex = None\n",
    "    for d in dataInfos[\"columns\"]:\n",
    "        if d[1] != int and d[1] != float: \n",
    "            columnIndex = dataInfos[\"columns\"].index(d)\n",
    "            break\n",
    "    \n",
    "    if columnIndex != None:\n",
    "        data.sort(key=lambda x: x[columnIndex])\n",
    "        data.reverse()\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "52c7e81a58432d44a1e41ae815c8bb35",
     "grade": true,
     "grade_id": "cell-a334c571e3d33bf1",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from nose.tools import assert_equal\n",
    "assert_equal(type(sortCSV(filePath)), list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1a5cae37f3c38f02d5c2f230dba749aa",
     "grade": false,
     "grade_id": "cell-1eff3872e1df78c6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Step 3b Sorting - pandas (2 points)\n",
    "\n",
    "Now, again using pandas, \n",
    "* define a similar function PandasSortCSV(filePath) which sorts the rows of the dataset by the same columns as in 3a, again in descending order of values. \n",
    "* This time, your function should return a pandas dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3ccd5893ed0a6d9e5f95dc3f1bee38c7",
     "grade": false,
     "grade_id": "cell-e63244f3196ef27f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def PandasSortCSV(filePath):\n",
    "    df = pd.read_csv(filePath)\n",
    "    dfTypes = df.select_dtypes(exclude=['int64','float64'])\n",
    "    dfSorted = df.sort_values(by=[dfTypes.columns.values[0]], ascending=False)\n",
    "    \n",
    "    return dfSorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "70988c8bcc888c4f32caabb205c393ec",
     "grade": true,
     "grade_id": "cell-b7dffcb7eeac0248",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from nose.tools import assert_equal\n",
    "assert_equal(isinstance(PandasSortCSV(filePath), pd.DataFrame), True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2dc983f66334690a0201f99aa36f5b18",
     "grade": false,
     "grade_id": "cell-b64c2a5902f2cd4e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Step 4a Aggregation and Grouping (4 points)\n",
    "\n",
    "Using pure Python, i.e. NOT using pandas define a function aggregateCSV(filePath) which does the following:\n",
    "* picks the left-most numeric column _X_ and the left-most non-numeric column _Y_ and\n",
    "* computes the __sum__ of the values of column _X_ __per__ value of column _Y_\n",
    "* Your function should return a dictionary holding the unique values of the non-numeric column as keys and the sums of the numeric column as values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0174aaf0d5c5cea7e98e8d9a03f6b661",
     "grade": false,
     "grade_id": "cell-af18f5282baa2eb7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def aggregateCSV(filePath):\n",
    "    with open(filePath, newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        data = list(reader)\n",
    "    \n",
    "    #get rid of header row\n",
    "    data.pop(0)\n",
    "    \n",
    "    dataInfos = analyzeCSV(filePath)\n",
    "    \n",
    "    columnIndexNonNumeric = None\n",
    "    columnIndexNumeric = None\n",
    "    for d in dataInfos[\"columns\"]:\n",
    "        if columnIndexNonNumeric == None and d[1] != int and d[1] != float: \n",
    "            columnIndexNonNumeric = dataInfos[\"columns\"].index(d)\n",
    "\n",
    "        elif columnIndexNumeric == None and (d[1] == int or d[1] == float):\n",
    "            columnIndexNumeric = dataInfos[\"columns\"].index(d)\n",
    "\n",
    "        elif columnIndexNonNumeric != None and columnIndexNumeric != None:\n",
    "            break\n",
    "    \n",
    "    groupDict = {}\n",
    "    if columnIndexNonNumeric != None and columnIndexNumeric != None:\n",
    "        for d in data:\n",
    "            if d[columnIndexNonNumeric] in groupDict:\n",
    "                groupDict[d[columnIndexNonNumeric]] += float(d[columnIndexNumeric])\n",
    "            else:\n",
    "                groupDict[d[columnIndexNonNumeric]] = float(d[columnIndexNumeric])\n",
    "    \n",
    "    return groupDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "13a14365b1d0c472bfc24476c293b77c",
     "grade": true,
     "grade_id": "cell-9351ddc641455e04",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from nose.tools import assert_equal\n",
    "assert_equal(type(aggregateCSV(filePath)), dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "12dad52410b23fc3bcd14cc0138960c4",
     "grade": false,
     "grade_id": "cell-ddbe334d3b102c49",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Step 4b Aggregation and Grouping - Pandas (2 points)\n",
    "\n",
    "Now, again using pandas, do the same as in 4a and call the function `PandasAggregateCSV` this time. It should return a pandas dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8bea89c3c32dae26000a3de8eb85abca",
     "grade": false,
     "grade_id": "cell-95103e5f3482a467",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def PandasAggregateCSV(filePath):\n",
    "    df = pd.read_csv(filePath)\n",
    "    dfNumeric = df.select_dtypes(include=['int64','float64'])\n",
    "    dfNonNumeric = df.select_dtypes(exclude=['int64','float64'])\n",
    "    dfSum = pd.DataFrame(df.groupby(dfNonNumeric.columns.values[0])[dfNumeric.columns.values[0]].sum())\n",
    "    \n",
    "    return dfSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b551aa2f161d51b63eb8d8981bccc82f",
     "grade": true,
     "grade_id": "cell-38b5b5dab09f96e2",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from nose.tools import assert_equal\n",
    "assert_equal(isinstance(PandasAggregateCSV(filePath), pd.DataFrame), True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
